{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11b2f015-f210-45be-88a6-83ff5e8620ce",
   "metadata": {},
   "source": [
    "### Checking for Requirements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d32304-cdf4-4507-8b87-227fa69739d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn\n",
    "#!pip install tqdm\n",
    "#!pip install seaborn\n",
    "#!python -m pip install --upgrade pip\n",
    "#!python -m pip install --upgrade setuptools wheel\n",
    "#!pip install streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37abc19b-b847-4afb-9420-bad89c51818e",
   "metadata": {},
   "source": [
    "### Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a20e2-d9f6-49cb-a7a1-8fc43b5d12ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import streamlit as st \n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm_notebook, tqdm\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report,confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.utils import all_estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb289d1-83d3-44be-bd0a-a291b6ca0787",
   "metadata": {},
   "source": [
    "### Providing file locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c8c249-86cf-461f-9398-5124d81c60c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "failuresloc      = \"C:/Users/Rohan/Downloads/AMLWorkshop-master/AMLWorkshop-master/Data/failures.csv\"\n",
    "telemetryloc     = \"C:/Users/Rohan/Downloads/AMLWorkshop-master/AMLWorkshop-master/Data/telemetry.csv\"\n",
    "errorsloc        = \"C:/Users/Rohan/Downloads/AMLWorkshop-master/AMLWorkshop-master/Data/errors.csv\"\n",
    "machinesloc      = \"C:/Users/Rohan/Downloads/AMLWorkshop-master/AMLWorkshop-master/Data/machines.csv\"\n",
    "telemetryfeatloc = \"C:/Users/Rohan/Downloads/AMLWorkshop-master/AMLWorkshop-master/Data/telemetryfeat.csv\"\n",
    "errorfeatloc     = \"C:/Users/Rohan/Downloads/AMLWorkshop-master/AMLWorkshop-master/Data/errorfeat.csv\"\n",
    "featuresloc      = \"C:/Users/Rohan/Downloads/AMLWorkshop-master/AMLWorkshop-master/Data/features.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7eace-3002-4342-a275-4843180b0a15",
   "metadata": {},
   "source": [
    "### Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2300a184-d206-4d09-be95-4e342787be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm_notebook(range(0,7), ncols = 1000, desc = \"Loading\"): \n",
    "    FailureDF       = pd.read_csv(failuresloc         ,low_memory = False)\n",
    "    TelemetryDF     = pd.read_csv(telemetryloc        ,low_memory = False)   \n",
    "    ErrorsDF        = pd.read_csv(errorsloc           ,low_memory = False)\n",
    "    MachinesDF      = pd.read_csv(machinesloc         ,low_memory = False)\n",
    "    TelemetryFeatDF = pd.read_csv(telemetryfeatloc    ,low_memory = False)\n",
    "    ErrorFeatDF     = pd.read_csv(errorfeatloc        ,low_memory = False)\n",
    "    FeaturesDF      = pd.read_csv(featuresloc         ,low_memory = False)\n",
    "print(\"Data Loaded\")\n",
    "\n",
    "FailureDF.name       = \"FailureDF\"\n",
    "FeaturesDF.name      = \"FeaturesDF\"\n",
    "TelemetryDF.name     = \"TelemetryDF\"\n",
    "ErrorsDF.name        = \"ErrorsDF\" \n",
    "MachinesDF.name      = \"MachinesDF\" \n",
    "TelemetryFeatDF.name = \"TelemetryFeatDF\"\n",
    "ErrorFeatDF.name     = \"ErrorFeatDF\"\n",
    "\n",
    "headlis = [FailureDF,TelemetryDF,ErrorsDF,TelemetryFeatDF,ErrorFeatDF,FeaturesDF]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851808ac-6cf3-45e7-b3c8-6a0e2983e96e",
   "metadata": {},
   "source": [
    "### Converting date time feature to a similar format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f5ee58-a97a-4286-8255-5a954c79842b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in headlis:\n",
    "    print(F\"{i.name}\", end = '\\n')\n",
    "    for j in tqdm_notebook(range(1),ncols = 1000, desc = \"Converting\"):\n",
    "        i['datetime'] = pd.to_datetime(i['datetime'])\n",
    "        i['datetime'] = i['datetime'].dt.strftime('%y-%m-%d')    \n",
    "        print(i['datetime'].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554f46b8-6d74-4cd3-affa-5c5cf1282269",
   "metadata": {},
   "source": [
    "### Sorting al data frames based on time stamps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caebe8b-7dba-4048-ad08-cab8fd4aaa45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('_'*140)\n",
    "for i in headlis:\n",
    "    if i.name == \"MachinesDF\":\n",
    "        continue\n",
    "    print(f\"{i.name} :\\n\")\n",
    "    cols = \"datetime\"\n",
    "    for j in tqdm_notebook(range(1),ncols = 1000, desc = \"Sorting\"): \n",
    "        i.sort_values(by = cols,inplace=True, axis=0)\n",
    "    print('_'*140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3045cff0-a586-415b-8c75-efcdac7594e1",
   "metadata": {},
   "source": [
    "### Merging all DF's Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8afac8-a642-46b9-88cc-7d8d2a0a42d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturesDF_ = TelemetryFeatDF.merge(FailureDF, on = 'datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ebfc31-1168-4241-a4bc-2ce573e90e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturesDF_ = FeaturesDF_.merge(ErrorsDF, on = 'datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005f87c-a1a3-4fe8-9893-ab72a715cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturesDF_ = FeaturesDF \n",
    "FeaturesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a425ff7-77c0-4c79-a14a-222b5520c863",
   "metadata": {},
   "source": [
    "### Exploring the DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2881ea21-01d8-4f02-919c-87bb9422ee47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in headlis:\n",
    "    print('_'*100)\n",
    "    print(f\"\\nHEAD ({i.name}) :\",end = '\\n')\n",
    "    print(i.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bd085e-d9c7-4ea9-8493-eb2ef83bfb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in headlis:\n",
    "    print('_'*100,f'\\n{i.name}')\n",
    "    print(f\"\\nTAIL ({i.name}) :\",end = '\\n')\n",
    "    print(i.tail(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928c5eb8-8431-4f32-8055-15f4bc803e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in headlis:\n",
    "    print('_'*100,f'\\n{i.name}')\n",
    "    print(f\"\\nDTYPES ({i.name}) :\",end = '\\n') \n",
    "    print(i.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e33921-4632-4cd0-b14f-60db4f8d5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in headlis:\n",
    "    print('_'*100,f'\\n{i.name}')\n",
    "    print(f\"\\nMISSVAL ({i.name}) :\",end = '\\n')\n",
    "    print(i.isna().sum())    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76b985-9382-4f14-a4ef-dd8a85575fa0",
   "metadata": {},
   "source": [
    "### Finding maximum and minimum timestamp date common in all DF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda1075-28eb-4672-89c5-953f9e2030b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "MinTS = []\n",
    "MaxTS = []\n",
    "for i in headlis:\n",
    "    if i.name == \"MachinesDF\":\n",
    "        continue\n",
    "    MinTS.append(i.iloc[0,0])\n",
    "    MaxTS.append(i.iloc[-1,0])\n",
    "print(MinTS)\n",
    "print(MaxTS)\n",
    "Minimum_Time_Stamp = max(MinTS)\n",
    "Maximum_Time_Stamp = min(MaxTS)\n",
    "print(f\"Minimum Time Stamp = {Minimum_Time_Stamp}\")\n",
    "print(f\"Maximum Time Stamp = {Maximum_Time_Stamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7ed8a9-8caa-4938-92eb-794ff5c33ea4",
   "metadata": {},
   "source": [
    "### Trimming all DF's to value points between min and max time stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443fe94-0603-4775-95cf-5379adf2aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in headlis:\n",
    "    print('_'*140)\n",
    "    i = i.loc[~((i['datetime'] <= Minimum_Time_Stamp) & (i['datetime'] >= Maximum_Time_Stamp))]\n",
    "    print(i.head(1))\n",
    "    print(i.tail(1))\n",
    "    print('_'*140)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898cdba-262e-424a-b403-06906ad7240f",
   "metadata": {},
   "source": [
    "### Dropping date time column after merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a487b1d-3809-40ef-80a5-98e145496299",
   "metadata": {},
   "outputs": [],
   "source": [
    "FeaturesDF.drop(columns= ['datetime'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e53f924-2e7f-43ec-8e9b-107b8de26f64",
   "metadata": {},
   "source": [
    "### Pairplots showing MEAN and SD overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2393e-9c3d-47e4-8b7d-514a2f01f5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = FeaturesDF[['voltmean','voltsd']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7ed85c-0439-4ae3-be5b-bd09f62ce87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = FeaturesDF[['rotatemean','rotatesd']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac22ad35-3451-488b-8d3f-97340689bfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data = FeaturesDF[['pressuremean','pressuresd']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ad3dc-ddb5-4a92-9229-06330e46c95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(FeaturesDF[['vibrationmean','vibrationsd']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048460ff-7200-44eb-a1d6-5ecbbd1fa08a",
   "metadata": {},
   "source": [
    "### Age based trend on voltage, rotation, vibration, pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dc116c-3a88-413e-aa3a-1cebffd7a0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = 'age', y = 'pressuremean', data = FeaturesDF, label = 'Pressure-Mean', color = 'orange')\n",
    "plt.xlabel(\"AGE\")\n",
    "plt.ylabel(\"Pressure\")\n",
    "plt.title(\"Age based trend graph\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c637b6a2-a8c9-48bc-bcbd-1f76e5514319",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = 'age', y = 'voltmean', data = FeaturesDF, label = 'Volt-Mean', color = 'red')\n",
    "plt.xlabel(\"AGE\")\n",
    "plt.ylabel(\"Voltage\")\n",
    "plt.title(\"Age based trend graph\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce7553d-cf32-4cae-9e19-eff69adc4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = 'age', y = 'rotatemean', data = FeaturesDF, label = 'Rotate-Mean', color = 'green')\n",
    "plt.xlabel(\"AGE\")\n",
    "plt.ylabel(\"Rotation\")\n",
    "plt.title(\"Age based trend graph\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7bc2a2-ebf9-4b4d-a42b-553cc795a116",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = 'age', y = 'vibrationmean', data = FeaturesDF, label = 'Vibration-Mean', color = 'blue')\n",
    "plt.xlabel(\"AGE\")\n",
    "plt.ylabel(\"Vibration\")\n",
    "plt.title(\"Age based trend graph\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be006a45-3bea-46c1-808b-941413e68827",
   "metadata": {},
   "source": [
    "### Encoding Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b014d-e5f3-4a07-b135-e8de6b355a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LE =  LabelEncoder()\n",
    "FeaturesDF['machineID'] = LE.fit_transform(FeaturesDF['machineID'])\n",
    "FeaturesDF['model']     = LE.fit_transform(FeaturesDF['model'])\n",
    "FeaturesDF.loc[FeaturesDF['failure'] == 'True' ,'failure'] = '1'\n",
    "FeaturesDF.loc[FeaturesDF['failure'] == 'False','failure'] = '0'\n",
    "FeaturesDF = FeaturesDF.astype({'failure' : int})\n",
    "FeaturesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8c1569-f974-4199-abe7-00d337579b54",
   "metadata": {},
   "source": [
    "### Ensuring that both the cases are equally provided in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339db8b6-d2cf-4d64-906e-ffd66d4aa37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTrue  = FeaturesDF.loc[FeaturesDF['failure'] == 1]\n",
    "XFalse = FeaturesDF.loc[FeaturesDF['failure'] == 0]\n",
    "XTrue  = XTrue[:5000][:]\n",
    "XTrue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1897a7cc-b6db-4ad8-bb96-be8a452c3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "XFalse = XFalse[:5000][:]\n",
    "XFalse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce2370-fa7e-4b0e-9f80-31fca1b691a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "XFinal = [XTrue,XFalse]\n",
    "FeaturesDF = pd.concat(XFinal, ignore_index = True)\n",
    "FeaturesDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeabe500-b16c-4dde-9cfc-3a7c8767dfa3",
   "metadata": {},
   "source": [
    "### Seperating Dataset into X and Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c32142-a30a-43ee-afda-953dd1df5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FeaturesDF.drop(columns= ['failure'])\n",
    "Y = FeaturesDF.iloc[:]['failure']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9adeb1e-46cf-4cc4-9e41-195a3545a28d",
   "metadata": {},
   "source": [
    "### Splitting Dataset into Training, Testing and Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865275a-3cf9-4a30-9031-9cd9f94750a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = X.iloc[::3][:]\n",
    "#Y = Y.iloc[::3][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e28906-90c8-45fa-a6eb-55de44bdc05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_val,y_train,y_val            = tts(X, Y, test_size = 0.30, random_state = 42)\n",
    "x_test,x_validate,y_test,y_validate    = tts(x_val, y_val, test_size = 0.30, random_state = 42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca55cbd-ea6d-440c-8ae4-602743e0a90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TRAINING DATA SET \\n','-_'*40)\n",
    "print(x_train.head(1),'\\n', x_train.shape, '\\n', '_'*80,'\\n', '\\n',y_train.head(1),y_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837e0e6e-08bf-4a96-b42e-c7cf517aab62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('TESTING DATA SET \\n','-_'*40)\n",
    "print(x_test.head(1),'\\n', x_test.shape, '\\n', '_'*80,'\\n', '\\n',y_test.head(1),y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64718a6-7c0a-4090-927d-9b0cd4223881",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('VALIDATION DATA SET \\n','-_'*40)\n",
    "print(x_validate.head(1),'\\n', x_validate.shape, '\\n', '_'*80,'\\n', '\\n',y_validate.head(1),y_validate.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8f1613-a653-4c1f-bf34-dbd016bdd1a8",
   "metadata": {},
   "source": [
    "### Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4552afe-0404-4a16-bfe2-9b6a42257494",
   "metadata": {},
   "outputs": [],
   "source": [
    "Scaler = StandardScaler()\n",
    "Scaler.fit(x_train)\n",
    "x_train    = Scaler.fit_transform(x_train)\n",
    "x_test     = Scaler.fit_transform(x_test)\n",
    "x_validate = Scaler.fit_transform(x_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591becca-0396-411e-a776-3f49c3a4bc8f",
   "metadata": {},
   "source": [
    "### Creating Machine Learning Models and evaluating which one is the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9e163-28c7-419c-8adf-1f19778fb013",
   "metadata": {},
   "outputs": [],
   "source": [
    "Classifiers = all_estimators(type_filter = 'classifier')\n",
    "\n",
    "ACCResults = []\n",
    "with tqdm(total = len(Classifiers), desc = 'Pls Wait') as pbar: \n",
    "    for name, Classifier_model in Classifiers:\n",
    "        pbar.set_description(f\"Running {name}\")\n",
    "        pbar.update(1)\n",
    "        try:\n",
    "            model  = Classifier_model()\n",
    "            model.fit(x_train,y_train)\n",
    "            y_pred = model.predict(x_test)\n",
    "            \n",
    "            accuracy_of_model = accuracy_score(y_test, y_pred)\n",
    "            report_of_model   = classification_report(y_test, y_pred,output_dict = True)\n",
    "    \n",
    "            ACCResults.append({\n",
    "                'Model'      : name,\n",
    "                'Accuracy'   : accuracy_of_model,\n",
    "                'Precision'  : report_of_model['weighted avg']['precision'], \n",
    "                'Recall'     : report_of_model['weighted avg']['recall'],\n",
    "                'F1-Score'   : report_of_model['weighted avg']['f1-score']\n",
    "            })\n",
    "            print(f\"MODEL : {name} ->\",\"\\033[32m PASSED\\033[0m\")\n",
    "        except Exception as e:\n",
    "            print(f\"MODEL : {name} ->\",\"\\033[31mFAILED\\033[0m\", \":\\033[33m Error : \\033[0m\",f\"\\033[48;2;106;0;0m{e}\\033[0m\")\n",
    "ACCDF = pd.DataFrame(ACCResults)\n",
    "ACCDF = ACCDF.sort_values(by = 'Accuracy', ascending = False)\n",
    "print('-_'*60)\n",
    "print(ACCDF)\n",
    "print('-_'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c4148f-446f-42e9-aae9-9e1a5bc583a2",
   "metadata": {},
   "source": [
    "### Running Decision Tree Classifier model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1641d8fd-a346-495c-893d-47a1bbc0350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,i in Classifiers:\n",
    "    if name == \"HistGradientBoostingClassifier\":\n",
    "        ML = i \n",
    "model = ML() \n",
    "model.fit(x_train,y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "y_valid= model.predict(x_validate)\n",
    "print(\"Test Report\\n\",'-_'*60)\n",
    "print(classification_report(y_test,y_pred))\n",
    "print()\n",
    "print(\"Validation Test Report\\n\",'-_'*60)\n",
    "print(classification_report(y_validate,y_valid))\n",
    "cm1 = confusion_matrix(y_test,y_pred)\n",
    "cm2 = confusion_matrix(y_validate,y_valid)\n",
    "CMD1 = ConfusionMatrixDisplay(confusion_matrix = cm1)\n",
    "CMD1.plot()\n",
    "CMD2 = ConfusionMatrixDisplay(confusion_matrix = cm2)\n",
    "CMD2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2916d6-0861-42c8-895e-dc1e60f5cc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran = pd.DataFrame(FeaturesDF.loc[FeaturesDF['failure'] == 0])\n",
    "ran = ran.sample(n=1)\n",
    "print(ran)\n",
    "ran = ran.drop(columns = ['failure'])\n",
    "print(ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbf145e-ac50-4878-b411-bf28939f0242",
   "metadata": {},
   "outputs": [],
   "source": [
    "ran = model.predict(ran)\n",
    "print(ran)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076a40c1-18d6-4baf-a6b9-6d334f0bea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand1 = pd.DataFrame(FeaturesDF.loc[FeaturesDF['failure'] == 1])\n",
    "rand1 = rand1.sample(n=1)\n",
    "print(rand1)\n",
    "rand1 = rand1.drop(columns = ['failure'])\n",
    "print(rand1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2d5193-e7da-4e4a-9a1e-31dd147e4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(rand1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06285c1-c764-44f3-ab40-a22b1c32242b",
   "metadata": {},
   "source": [
    "### Download ML Model as pkg for Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eb3dce-93d6-4fd6-b5d7-402424b5496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "XTRDF = pd.DataFrame(x_train)\n",
    "with tqdm(range(2), desc = \"Exporting Pickle File\") as pbar:\n",
    "    with open(\"D:/PMUI/MODEL_FILES/RFCV1.pkl\", 'wb') as files: \n",
    "        pickle.dump(model, files)\n",
    "        pbar.set_description(\"Export Successfull\")\n",
    "        pbar.update(1)\n",
    "    with open(\"D:/PMUI/MODEL_FILES/xtr.csv\", 'wb') as files: \n",
    "        XTRDF.to_csv(files)\n",
    "        pbar.set_description(\"Export Successfull\")\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887dfbec-db34-4883-a418-4369d7b425ec",
   "metadata": {},
   "source": [
    "### Streamlit Deployment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe2e344-94a6-494a-af3f-98aa273110a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "# import pandas as pd\n",
    "# import pickle\n",
    "# import json\n",
    "# import requests\n",
    "# from streamlit_lottie import st_lottie\n",
    "# from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# fail_logo_path = \"D:/PMUI/fail1.json\"\n",
    "# pass_logo_path = \"D:/PMUI/pass.json\"\n",
    "# pickle_url = \"https://github.com/RohanGJ/PMUMLAi/raw/refs/heads/master/RFCV1.pkl\"\n",
    "\n",
    "# def load_lottiefile(filepath: str):\n",
    "#   with open(filepath, \"r\") as f:\n",
    "#     return json.load(f)\n",
    "\n",
    "# def load_model_from_github(url):\n",
    "#   response = requests.get(url)\n",
    "#   response.raise_for_status()\n",
    "#   model = pickle.loads(response.content)\n",
    "#   st.error(f\"MODEL LOADED from  : {url}\")\n",
    "#   return model\n",
    "\n",
    "# model = load_model_from_github(pickle_url)\n",
    "\n",
    "# st.title('MACHINE LEARNING')\n",
    "# st.info(\"Preventine Maintanance\")\n",
    "\n",
    "# E1C,E2C,E3C,E4C,E5C = 0,0,0,0,0\n",
    "\n",
    "# Vmean,Rmean,Pmean,VBmean = 0.00,0.00,0.00,0.00\n",
    "\n",
    "# Vsd,Rsd,Psd,VBsd = 0.00,0.00,0.00,0.00\n",
    "\n",
    "# tab1,tab2,tab3,tab4,tab5,tab6 = st.tabs([\"Error_count\",\"Voltage\",\"Rotations\",\"Pressure\",\"Vibration\",\"MISC\"])\n",
    "\n",
    "# with tab1:\n",
    "#   st.write('Provide Error Counts for each attributes')\n",
    "#   E1C    = st.selectbox('Error1Count',[0,1,2])\n",
    "#   E2C    = st.selectbox('Error2Count',[0,1,2])\n",
    "#   E3C    = st.selectbox('Error3Count',[0,1,2])\n",
    "#   E4C    = st.selectbox('Error4Count',[0,1,2])\n",
    "#   E5C    = st.selectbox('Error5Count',[0,1,2])\n",
    "  \n",
    "# with tab2:\n",
    "#   st.write('Provide Mean and SD of VTin')\n",
    "#   Vmean  = st.slider('Mean Voltage',150.00,220.00,170.00)\n",
    "#   Vsd    = st.slider('Standard Deviation (Voltage)',6.50,27.50,14.50)\n",
    "\n",
    "# with tab3:\n",
    "#   st.write('Provide Mean and SD of RTin')\n",
    "#   Rmean  = st.slider('Mean Rotation',260.00,500.00,450.00)\n",
    "#   Rsd    = st.slider('Standard Deviation (Rotation)',19.00,105.00,50.00)\n",
    "\n",
    "# with tab4:\n",
    "#   st.write('Provide Mean and SD of PRin')\n",
    "#   Pmean  = st.slider('Mean Pressure',90.00,155.00,100.00)\n",
    "#   Psd    = st.slider('Standard Deviation (Pressure)',4.00,29.00,9.50)\n",
    "\n",
    "# with tab5:\n",
    "#   st.write('Provide Mean and SD of VBin')\n",
    "#   VBmean  = st.slider('Mean Vibration',35.00,65.00,40.00)\n",
    "#   VBsd    = st.slider('Standard Deviation (Vibration)',2.00,14.00,5.00)\n",
    "# with tab6:\n",
    "#   MID    = st.slider('Machine ID',0,99,1)\n",
    "#   AGE    = st.slider('Age',0,20,1)\n",
    "#   modrang = list(range(0,100))\n",
    "#   MODEL  = st.selectbox('Model', modrang)\n",
    "\n",
    "# FinLis = {\n",
    "#       'machineID'    : [MID],\n",
    "#       'voltmean'     : [Vmean],\n",
    "#       'rotatemean'   : [Rmean],\n",
    "#       'pressuremean' : [Pmean],\n",
    "#       'vibrationmean': [VBmean], \n",
    "#       'voltsd'       : [Vsd],\n",
    "#       'rotatesd'     : [Rsd], \n",
    "#       'pressuresd'   : [Psd], \n",
    "#       'vibrationsd'  : [VBsd],\n",
    "#       'error1count'  : [E1C],\n",
    "#       'error2count'  : [E2C], \n",
    "#       'error3count'  : [E3C], \n",
    "#       'error4count'  : [E4C], \n",
    "#       'error5count'  : [E5C],\n",
    "#       'model'        : [MODEL], \n",
    "#       'age'          : [AGE], \n",
    "#   }\n",
    "\n",
    "# STDF = pd.DataFrame(FinLis)\n",
    "\n",
    "# def color_df(val):\n",
    "#   if val > 0 and val < 100:\n",
    "#     color = 'blue'\n",
    "#   elif val > 99:\n",
    "#     color = 'green'\n",
    "#   elif val == 0:\n",
    "#     color = 'red'\n",
    "#   else:\n",
    "#     color = 'orange'\n",
    "#   return f'background-color: {color}'\n",
    "\n",
    "# st.info(\"USER INPUTS :\")\n",
    "# st.dataframe(STDF.iloc[:,[0,1,2,3,4,5,6,15]].style.applymap(color_df))\n",
    "# st.dataframe(STDF.iloc[:,7:-1].style.applymap(color_df))\n",
    "# #st.write(STDF[:][:8])\n",
    "\n",
    "# pred = []\n",
    "# STDF = STDF.values\n",
    "# pred = list(model.predict(STDF))\n",
    "\n",
    "# col1, col2 = st.columns(2, gap = \"small\")\n",
    "\n",
    "# col1.info(\"MODEL Eval\")\n",
    "# col1.subheader(\"Prediction : \")\n",
    "# col1.write(model.predict(STDF))\n",
    "\n",
    "# col1.subheader(\"Prediction Probability :\")\n",
    "# col1.write(model.predict_proba(STDF))\n",
    "  \n",
    "# lottie_pass = load_lottiefile(pass_logo_path)\n",
    "# lottie_fail = load_lottiefile(fail_logo_path)\n",
    "\n",
    "# with col2:\n",
    "#   st.info(\"STATUS\")\n",
    "#   if pred[0] == 0:\n",
    "#     st_lottie(lottie_pass, speed = 0.75, loop = False)\n",
    "#   elif pred[0] == 1:\n",
    "#    st_lottie(lottie_fail, speed = 0.75, loop = True, reverse = True) \n",
    "#   else:\n",
    "#     st.info(\"Press Run model after selecting inputs\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
